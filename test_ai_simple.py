#!/usr/bin/env python3
"""
Simple test script for AI service implementation
Tests only the AI service without other dependencies
"""

import asyncio
import os
import sys
import json
from pathlib import Path

# Add backend to path
backend_path = Path(__file__).parent / "backend"
sys.path.insert(0, str(backend_path))

async def test_ai_service_direct():
    """Test AI service directly without other service dependencies"""
    try:
        print("ğŸ¤– Testing AI Service Implementation")
        print("=" * 50)
        
        # Import dependencies directly
        from openai import AsyncOpenAI
        from core.config import settings
        
        # Test OpenAI connection
        print("\nğŸ”— Testing OpenAI Connection")
        if not settings.openai_api_key:
            print("âŒ No OpenAI API key configured")
            return False
            
        print(f"âœ… OpenAI API Key: {settings.openai_api_key[:10]}...")
        print(f"âœ… Model: {settings.openai_model}")
        print(f"âœ… Temperature: {settings.openai_temperature}")
        print(f"âœ… Max tokens: {settings.openai_max_tokens}")
        
        # Test simple AI call
        client = AsyncOpenAI(api_key=settings.openai_api_key)
        
        # Use Chat Completions for initial test (more stable)
        print("\nğŸ“ Testing Basic OpenAI API Call")
        response = await client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "user", "content": "What is 2+2? Reply with just the number."}
            ],
            max_tokens=10
        )
        
        result = response.choices[0].message.content.strip()
        print(f"âœ… OpenAI Response: '{result}'")
        
        if "4" in result:
            print("âœ… OpenAI API working correctly")
        else:
            print(f"âš ï¸ Unexpected response: {result}")
        
        # Test Responses API if available
        print("\nğŸ”„ Testing Responses API")
        try:
            responses_test = await client.responses.create(
                model="gpt-4.1",
                input=[
                    {"role": "user", "content": [{"type": "input_text", "text": "Hello, respond with 'AI working'"}]}
                ],
                max_output_tokens=20
            )
            
            if hasattr(responses_test, 'output_text'):
                print(f"âœ… Responses API: {responses_test.output_text}")
            else:
                print(f"âœ… Responses API: {responses_test.output}")
                
        except Exception as e:
            print(f"âš ï¸ Responses API not available: {e}")
            print("ğŸ’¡ Will use Chat Completions API instead")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ Test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

async def test_function_definitions():
    """Test function definitions for tool calling"""
    print("\nğŸ”§ Testing Function Definitions")
    print("=" * 35)
    
    # Test function definitions format
    tools = [
        {
            "type": "function",
            "function": {
                "name": "get_truck_location",
                "description": "Get current location and status of a specific truck",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "truck_number": {
                            "type": "string",
                            "description": "The truck number (e.g., T11985LA)"
                        }
                    },
                    "required": ["truck_number"]
                }
            }
        }
    ]
    
    print("âœ… Function definitions structure valid")
    print(f"âœ… Example function: {tools[0]['function']['name']}")
    
    # Test JSON parsing (security check)
    test_args = '{"truck_number": "T11985LA"}'
    try:
        parsed = json.loads(test_args)
        print(f"âœ… JSON parsing secure: {parsed}")
    except json.JSONDecodeError as e:
        print(f"âŒ JSON parsing failed: {e}")
        return False
    
    # Test eval() vulnerability is fixed
    malicious_input = '{"truck_number": "__import__(\'os\').system(\'echo HACKED\')"}'
    try:
        parsed = json.loads(malicious_input)
        print(f"âœ… Malicious input safely parsed as: {parsed}")
        print("âœ… No code execution vulnerability")
    except:
        print("âŒ JSON parsing issue")
        return False
    
    return True

async def main():
    """Run all tests"""
    print("ğŸš€ Starting Simple AI Service Tests")
    print("=" * 60)
    
    # Check environment
    if not os.getenv('OPENAI_API_KEY'):
        print("âŒ OPENAI_API_KEY not found in environment")
        return False
    
    # Run tests
    tests = [
        ("Function Definitions", test_function_definitions),
        ("AI Service Direct", test_ai_service_direct),
    ]
    
    results = []
    for test_name, test_func in tests:
        print(f"\n{'='*15} {test_name} {'='*15}")
        result = await test_func()
        results.append((test_name, result))
    
    # Summary
    print("\n" + "="*60)
    print("ğŸ“Š TEST SUMMARY")
    print("="*60)
    
    for test_name, passed in results:
        status = "âœ… PASSED" if passed else "âŒ FAILED"
        print(f"{test_name}: {status}")
    
    all_passed = all(result for _, result in results)
    print(f"\nOverall: {'âœ… ALL TESTS PASSED' if all_passed else 'âŒ SOME TESTS FAILED'}")
    
    if all_passed:
        print("\nğŸ‰ AI Service foundation is working!")
        print("ğŸ’¡ Next steps:")
        print("   1. Fix Slack configuration issue")
        print("   2. Test with real database connections")
        print("   3. Validate function calling with truck data")
    
    return all_passed

if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)